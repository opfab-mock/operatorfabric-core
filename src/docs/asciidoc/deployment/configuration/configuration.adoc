// Copyright (c) 2018-2020 RTE (http://www.rte-france.com)
// See AUTHORS.txt
// This document is subject to the terms of the Creative Commons Attribution 4.0 International license.
// If a copy of the license was not distributed with this
// file, You can obtain one at https://creativecommons.org/licenses/by/4.0/.
// SPDX-License-Identifier: CC-BY-4.0




:springboot_doc: https://docs.spring.io/spring-boot/docs/2.1.2.RELEASE/
:mongo_doc: https://docs.mongodb.com/manual/reference/
:spring_kafka_doc: https://docs.spring.io/spring-kafka/reference/html/
//TODO Check if versions are correct

= Configuration

OperatorFabric has multiple services to configure. 

See the
ifdef::single-page-doc[<<architecture, architecture documentation>>]
ifndef::single-page-doc[<<{gradle-rootdir}/documentation/current/architecture/index.adoc#architecture, architecture documentation>>]
for more information on the different services.

All services are SpringBoot applications and use jetty as an embedded servlet container. As such, they share some common
configuration which is described in the following documentation:

 * link:{springboot_doc}/reference/htmlsingle/[Springboot documentation]
 * link:{springboot_doc}/reference/htmlsingle/#boot-features-external-config[Springboot external configuration]
 * link:{springboot_doc}/reference/htmlsingle/#common-application-properties[Common application properties from Springboot documentation]

Configuration is centralized in the *config* directory, the *dev* sub-directory is specific to development environments
while the *docker* sub-directory is a specific configuration meant for use in a full docker environment.

== Business service configuration

=== Shared business service configuration

The configuration shared by all business services is in a yaml file, you can find an example with the file
/config/docker/common-docker.yml.
In this file you will find, among others, the parameters below :

|===
|name|default|mandatory?|Description

|operatorfabric.businessLogActivated|false|no|Indicates whether or not operatorfabric should record business logs

|===

=== Business service specific configurations

Each business service has a specific yaml configuration file. It should a least contain the name of the service:

[source, yaml]
----
spring:
  application:
    name: businessconfig
----

It can contain references to other services as well, for example :
[source, yaml]
----
users:
  ribbon:
    listOfServers: users:8080
----

Examples of configuration of each business service can be found either under config/docker or config/dev depending on
the type of deployment you're looking for.

==== Businessconfig service

The businessconfig service has this specific property : 

|===
|name|default|mandatory?|Description

|operatorfabric.businessconfig.storage.path|null|no|File path to data storage folder

|===


==== Users service

The user service has these specific properties :

|===
|name|default|mandatory?|Description

|operatorfabric.users.default.users|null|no| Array of user objects to create upon startup if they don't exist
|operatorfabric.users.default.user-settings|null|no| Array of user settings objects to create upon startup if they don't exist
|operatorfabric.users.default.groups|null|no| Array of group objects to create upon startup if they don't exist
|operatorfabric.users.default.entities|null|no| Array of entity objects to create upon startup if they don't exist

|===


==== Cards-publication service

The cards-publication service has these specific properties :

|===
|name|default|mandatory?|Description

|checkPerimeterForResponseCard|true|no|If false, OperatorFabric will not check that a user has write rights on a process/state to respond to a card
|spring.kafka.consumer.group-id |null|no| If set, support for receiving cards via Kafka is enabled
|spring.deserializer.key.delegate.class |io.confluent.kafka.serializers.
|KafkaAvroDeserializer|yes| Deserializer used to convert the received bytes into objects
|opfab.kafka.topics.topicname |opfab|no|Name of the topic to read the messages from
|schema.registry.url|http://localhost:8081|yes|URL of the schema registry. Can be set to the empty string "" is no registry is used
|spring.kafka.producer.bootstrap-servers|http://localhost:9092|no|comma seperated list of URL(s) of the broker(s) / bootstrap server(s)
|===


include::web-ui_configuration.adoc[leveloffset=+1]


[[opfab_spec_conf]]
include::security_configuration.adoc[leveloffset=+1]

== OperatorFabric Mongo configuration

We only use URI configuration for mongo through the usage of the ```spring.data.mongodb.uris```,
it allows us to share the same configuration behavior for simple or cluster
configuration and with both spring classic and reactive mongo configuration.
See link:{mongo_doc}connection-string/[mongo connection string] for the complete URI syntax.

=== Define time to live for archived cards

By default, archived cards will remain stored in the database forever. It is possible to have them automatically
removed after a specified duration by using the link:https://docs.mongodb.com/manual/core/index-ttl/[TTL index feature of mongoDB] on their publishDate field.

For example, to have cards expire after 10 days (864000s), enter the following commands in the mongo shell:

[source,shell]
----
use operator-fabric
db.archivedCards.createIndex( { "publishDate": 1 }, { expireAfterSeconds: 864000 } )
----

IMPORTANT: You cannot use createIndex() to change the value of expireAfterSeconds of an existing index.
Instead use the link:https://docs.mongodb.com/manual/reference/command/collMod/#dbcmd.collMod[collMod] database command in conjunction with the index collection flag. Otherwise, to
change the value of the option of an existing index, you must drop the index first and recreate.

== OperatorFabric Kafka configuration

Next to publishing cards to OperatorFabric using the REST API, OperatorFabric also supports publishing cards via a Kafka Topic. In the default configuration Kafka is disabled.
To enable Kafka you need to set the consumer group to the consumer group you assign to the OpFab Kafka consumer. This can be any group-id, as long as it isn't used by other consumers
(unless you explicitly want multiple consumers for the same group).

You can set the group_id by uncommenting the `kafka.consumer.group_id` in the `cards-publication.yml`

[source, yaml]
----
  kafka:
    consumer:
      group-id: opfab-command
----
By default, the consumer will consume messages from the `opfab` topic.
See link:{spring_kafka_doc}[Spring for Apache Kafka] for more information on the Spring Kafka implementation.

With the default settings, the Kafka consumer expects a broker running on http//127.0.0.1:9092 and a schema registry on http://127.0.0.1:8081.

Response cards are not (yet) returned via Kafka, but by the URL specified in the cards-publication yml file.

Note that enabling Kafka does not disable the REST interface.
